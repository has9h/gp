{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\ProgramData\\\\Anaconda3\\\\python.exe'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find running python kernel\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from matplotlib import animation, cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(X1, X2, l=1.0, sigma_f=1.0):\n",
    "    \"\"\"\n",
    "    Isotropic squared exponential kernel.\n",
    "    \n",
    "    Args:`\n",
    "\n",
    "    Returns:\n",
    "        (m x n) matrix.\n",
    "    \"\"\"\n",
    "    sqdist = np.sum(X1**2, 1).reshape(-1, 1) + np.sum(X2**2, 1) - 2 * np.dot(X1, X2.T)\n",
    "    return sigma_f**2 * np.exp(-0.5 / l**2 * sqdist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gp(mu, cov, X, X_train=None, Y_train=None, samples=[]):\n",
    "    X = X.ravel()\n",
    "    mu = mu.ravel()\n",
    "    uncertainty = 1.96 * np.sqrt(np.diag(cov))\n",
    "    \n",
    "    plt.fill_between(X, mu + uncertainty, mu - uncertainty, alpha=0.1)\n",
    "    plt.plot(X, mu, label='Mean')\n",
    "    for i, sample in enumerate(samples):\n",
    "        plt.plot(X, sample, lw=1, ls='--', label=f'Sample {i+1}')\n",
    "    if X_train is not None:\n",
    "        plt.plot(X_train, Y_train, 'rx')\n",
    "    plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior on 1D Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finite number of points\n",
    "X = np.arange(-5, 5, 0.2).reshape(-1, 1)\n",
    "\n",
    "# Mean and covariance of the prior\n",
    "mu = np.zeros(X.shape)\n",
    "cov = kernel(X, X)\n",
    "\n",
    "# Draw three samples from the prior\n",
    "samples = np.random.multivariate_normal(mu.ravel(), cov, 3)\n",
    "\n",
    "# Plot GP mean, uncertainty region and samples \n",
    "# plot_gp(mu, cov, X, samples=samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posterior\n",
    "\n",
    "## Prediction from noise-free training data\n",
    "\n",
    "Given a training dataset with noise-free function values $\\mathbf{f}$ at inputs $\\mathbf{X}$, a GP prior can be converted into a GP posterior $p(\\mathbf{f}^* \\vert \\mathbf{X}^*, \\mathbf{X}, \\mathbf{f})$ which can then be used to make predictions $\\mathbf{f}^*$ at new inputs $\\mathbf{X}^*$. By definition of a GP, the joint distribution of observed values $\\mathbf{f}$ and predictions $\\mathbf{f}^*$ is again a Gaussian which can be partitioned into\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "    \\mathbf{f} \\\\\n",
    "    \\mathbf{f}_*\n",
    "\\end{pmatrix} \\sim \\mathcal{N}\n",
    "\\left(\\boldsymbol{0},\n",
    "\\begin{pmatrix}\n",
    "    \\mathbf{K} & \\mathbf{K}_* \\\\\n",
    "    \\mathbf{K}_*^T & \\mathbf{K}_{**}\n",
    "\\end{pmatrix}\n",
    "\\right)\\tag{2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(\\mathbf{f}_* \\lvert \\mathbf{X}_*,\\mathbf{X},\\mathbf{f}) &= \\mathcal{N}(\\mathbf{f}_* \\lvert \\boldsymbol{\\mu}_*, \\boldsymbol{\\Sigma}_*) \\\\\n",
    "\\boldsymbol{\\mu_*} &= \\mathbf{K}_*^T \\mathbf{K}^{-1} \\mathbf{f} \\\\\n",
    "\\boldsymbol{\\Sigma_*} &= \\mathbf{K}_{**} - \\mathbf{K}_*^T \\mathbf{K}^{-1} \\mathbf{K}_*\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv\n",
    "\n",
    "def posterior(X_s, X_train, Y_train, l=1.0, sigma_f=1.0, sigma_y=1e-8):\n",
    "    \"\"\"\n",
    "    Computes the suffifient statistics of the posterior distribution \n",
    "    from m training data X_train and Y_train and n new inputs X_s.\n",
    "    \n",
    "    Args:\n",
    "        X_s: New input locations (n x d).\n",
    "        X_train: Training locations (m x d).\n",
    "        Y_train: Training targets (m x 1).\n",
    "        l: Kernel length parameter.\n",
    "        sigma_f: Kernel vertical variation parameter.\n",
    "        sigma_y: Noise parameter.\n",
    "    \n",
    "    Returns:\n",
    "        Posterior mean vector (n x d) and covariance matrix (n x n).\n",
    "    \"\"\"\n",
    "    K = kernel(X_train, X_train, l, sigma_f) + sigma_y**2 * np.eye(len(X_train))\n",
    "    K_s = kernel(X_train, X_s, l, sigma_f)\n",
    "    K_ss = kernel(X_s, X_s, l, sigma_f) + 1e-8 * np.eye(len(X_s))\n",
    "    K_inv = inv(K)\n",
    "    \n",
    "    # Equation (7)\n",
    "    mu_s = K_s.T.dot(K_inv).dot(Y_train)\n",
    "\n",
    "    # Equation (8)\n",
    "    cov_s = K_ss - K_s.T.dot(K_inv).dot(K_s)\n",
    "    \n",
    "    return mu_s, cov_s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise free training data\n",
    "X_train = np.array([-4, -3, -2, -1, 1]).reshape(-1, 1)\n",
    "Y_train = np.sin(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean and covariance of the posterior distribution\n",
    "mu_s, cov_s = posterior(X, X_train, Y_train)\n",
    "\n",
    "samples = np.random.multivariate_normal(mu_s.ravel(), cov_s, 3)\n",
    "# plot_gp(mu_s, cov_s, X, X_train=X_train, Y_train=Y_train, samples=samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D Prediction from noisy training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.4\n",
    "\n",
    "# Noisy training data\n",
    "X_train = np.arange(-3, 4, 1).reshape(-1, 1)\n",
    "Y_train = np.sin(X_train) + noise * np.random.randn(*X_train.shape)\n",
    "\n",
    "# Compute mean and covariance of the posterior distribution\n",
    "mu_s, cov_s = posterior(X, X_train, Y_train, sigma_y=noise)\n",
    "\n",
    "samples = np.random.multivariate_normal(mu_s.ravel(), cov_s, 3)\n",
    "plot_gp(mu_s, cov_s, X, X_train=X_train, Y_train=Y_train, samples=samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal values for the kernel parameters $l$ and $\\sigma_f$, as well as the noise parameter $\\sigma_y$ can be estimated by maximizing the log marginal likelihood which is given by\n",
    "\n",
    "$$\n",
    "\\log p(\\mathbf{y} \\lvert \\mathbf{X}) = \n",
    "\\log \\mathcal{N}(\\mathbf{y} \\lvert \\boldsymbol{0}, \\mathbf{K}_y) =\n",
    "-\\frac{1}{2} \\mathbf{y}^T \\mathbf{K}_y^{-1} \\mathbf{y} \n",
    "-\\frac{1}{2} \\log \\begin{vmatrix}\\mathbf{K}_y\\end{vmatrix} \n",
    "-\\frac{N}{2} \\log(2\\pi)\n",
    "$$\n",
    "\n",
    "We will minimize the negative log marginal likelihood w.r.t. parameters $l$ and $\\sigma_f$. $\\sigma_y$ is set to the known noise level of the data. If the noise level is unknown, Ïƒy can be estimated as well along with the other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import cholesky, det\n",
    "from scipy.linalg import solve_triangular\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def nll_fn(X_train, Y_train, noise, naive=True):\n",
    "    \"\"\"\n",
    "    Returns a function that computes the negative log marginal\n",
    "    likelihood for training data X_train and Y_train and given\n",
    "    noise level.\n",
    "\n",
    "    Args:\n",
    "        X_train: training locations (m x d).\n",
    "        Y_train: training targets (m x 1).\n",
    "        noise: known noise level of Y_train.\n",
    "        naive: if True use a naive implementation of Eq. (11), if\n",
    "               False use a numerically more stable implementation.\n",
    "\n",
    "    Returns:\n",
    "        Minimization objective.\n",
    "    \"\"\"\n",
    "    \n",
    "    Y_train = Y_train.ravel()\n",
    "    \n",
    "    def nll_naive(theta):\n",
    "        # Naive implementation of the log marginal likelihood. Works well \n",
    "        # for the examples in this article but is numerically less stable \n",
    "        # compared to the implementation in nll_stable below.\n",
    "        K = kernel(X_train, X_train, l=theta[0], sigma_f=theta[1]) + \\\n",
    "            noise**2 * np.eye(len(X_train))\n",
    "        return 0.5 * np.log(det(K)) + \\\n",
    "               0.5 * Y_train.dot(inv(K).dot(Y_train)) + \\\n",
    "               0.5 * len(X_train) * np.log(2*np.pi)\n",
    "        \n",
    "    def nll_stable(theta):\n",
    "        # Numerically more stable implementation of the log marginal likelihood \n",
    "        # as described in http://www.gaussianprocess.org/gpml/chapters/RW2.pdf, \n",
    "        # Section 2.2, Algorithm 2.1.\n",
    "        \n",
    "        K = kernel(X_train, X_train, l=theta[0], sigma_f=theta[1]) + \\\n",
    "            noise**2 * np.eye(len(X_train))\n",
    "        L = cholesky(K)\n",
    "        \n",
    "        S1 = solve_triangular(L, Y_train, lower=True)\n",
    "        S2 = solve_triangular(L.T, S1, lower=False)\n",
    "        \n",
    "        return np.sum(np.log(np.diagonal(L))) + \\\n",
    "               0.5 * Y_train.dot(S2) + \\\n",
    "               0.5 * len(X_train) * np.log(2*np.pi)\n",
    "\n",
    "    if naive:\n",
    "        return nll_naive\n",
    "    else:\n",
    "        return nll_stable\n",
    "\n",
    "# Minimize the negative log-likelihood w.r.t. parameters l and sigma_f.\n",
    "# We should actually run the minimization several times with different\n",
    "# initializations to avoid local minima but this is skipped here for\n",
    "# simplicity.\n",
    "res = minimize(nll_fn(X_train, Y_train, noise), [1, 1], \n",
    "               bounds=((1e-5, None), (1e-5, None)),\n",
    "               method='L-BFGS-B')\n",
    "\n",
    "# Store the optimization results in global variables so that we can\n",
    "# compare it later with the results from other implementations.\n",
    "l_opt, sigma_f_opt = res.x\n",
    "\n",
    "# Compute posterior mean and covariance with optimized kernel parameters and plot the results\n",
    "mu_s, cov_s = posterior(X, X_train, Y_train, l=l_opt, sigma_f=sigma_f_opt, sigma_y=noise)\n",
    "# plot_gp(mu_s, cov_s, X, X_train=X_train, Y_train=Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx, ry = np.arange(-5, 5, 0.3), np.arange(-5, 5, 0.3)\n",
    "gx, gy = np.meshgrid(rx, rx)\n",
    "\n",
    "noise_2D = 0.1\n",
    "\n",
    "X_2D_train = np.random.uniform(-4, 4, (100, 2))\n",
    "Y_2D_train = np.sin(0.5 * np.linalg.norm(X_2D_train, axis=1)) + \\\n",
    "             noise_2D * np.random.randn(len(X_2D_train))\n",
    "Y_2D_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Meson data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_content = np.random.randint(2, size=(10))\n",
    "isospin = np.linspace(0, 1.5, 4) \n",
    "ang_momentum = np.arange(0, 4.5, 0.5) \n",
    "parity = np.array([-1, 1])\n",
    "\n",
    "# Create new data\n",
    "def choose(quantity):\n",
    "    return np.array(np.random.choice(quantity))\n",
    "\n",
    "X = np.empty([50, 13])\n",
    "\n",
    "for i in range(50):\n",
    "    X[i] = np.append(q_content, (choose(isospin), choose(ang_momentum), choose(parity)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Gaussian processes, we need to add an additional value to distinguish between different particles that constitute the same vector, ranked in order of their masses. From the paper, we will also be using the squared exponential (SE) and rational quadratic (RQ) kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.model_selection import LeaveOneOut, train_test_split\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF, RationalQuadratic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question: How do you handle K-short and K-long?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Hasnain\\\\Uni\\\\AGenCy Lab\\\\Codebase\\\\gp\\\\freitas-krasserm-turner'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../baryons-from-mesons/GaussianProcess/data/mesoninputs.dat'\n",
    "target_file = '../baryons-from-mesons/GaussianProcess/data/mMass.dat'\n",
    "test_file = '../baryons-from-mesons/GaussianProcess/data/baryoninputs.dat'\n",
    "test_target_file = '../baryons-from-mesons/GaussianProcess/data/bMass.dat'\n",
    "\n",
    "data = np.loadtxt(data_file)\n",
    "target = np.loadtxt(target_file)\n",
    "test = np.loadtxt(test_file)\n",
    "test_target = np.loadtxt(test_target_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out needed test data\n",
    "\n",
    "**Baryons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.where((test == (0, 0, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0.5, 1, 0)).all(axis=1))\n",
    "\n",
    "# 7 baryons: p, n, lambda^{0}, sigma^{+}, sigma^{0}, sigma^{-}, delta^{++}\n",
    "indices = [0, 1, 2, 5, 6, 7, 24]\n",
    "X_test = test[indices]\n",
    "Y_test = test_target[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3: Recreate Tables 2-4\n",
    "\n",
    "**Missing values existing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(pd.DataFrame(data=data).drop(indices))\n",
    "Y_train = np.delete(target, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 980.  , 1370.  , 2535.11, 2535.11])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.88755257, 7.22256602, 7.83799231, 7.83799231])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.where((data == (0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0)).all(axis=1))\n",
    "\n",
    "# Mesons found in dataset: a_0, f_0, D_{s1}^{-}, D_{s1}^{+}\n",
    "indices = [10, 28, 137, 138]\n",
    "X_test = data[indices]\n",
    "Y_test = target[indices]\n",
    "\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 938.27210729,  939.56781663, 1115.68071016, 1189.37114875,\n",
       "       1192.64642084, 1197.4505092 , 1231.99489449])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "np.exp(test_target[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without the following unknown quark contents:\n",
    "# f2, a2(1320), Ï€2, Î·2(1645), a2(1700), Î·2(1870) \n",
    "X = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, -1, 0],\n",
    "              [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, -1, 0],\n",
    "              [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, -1, 0], # Î·\n",
    "              [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, -1, 1], # Î·'\n",
    "              [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, -1, 0],\n",
    "              [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0],\n",
    "              [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, -1, 0],\n",
    "              [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0.5, 0, -1, 0],\n",
    "              [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0.5, 0, -1, 0],\n",
    "              [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0.5, 0, -1, 0],\n",
    "              [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0.5, 0, -1, 0],\n",
    "              [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0.5, 0, -1, 0], #K-short\n",
    "              [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0.5, 0, -1, 0], #K-long\n",
    "              [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0.5, 1, -1, 0],\n",
    "              [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0.5, 1, -1, 0],\n",
    "              [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0.5, 1, -1, 0],\n",
    "              [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0.5, 1, -1, 0]])\n",
    "\n",
    "Y = np.array([139.57039, 139.57039, 134.9768, 547.862, 957.78, 775.4, 775.4, 775.49, 782.65, 1019.461,\n",
    "              493.677, 493.677, 497.611, 497.611, 497.614, 497.614, 891.66, 891.66, 895.55, 895.55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With all particles\n",
    "# Unknown quark contents set to 0\n",
    "X = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, -1, 0],\n",
    "              [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, -1, 0],\n",
    "              [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, -1, 0],\n",
    "              [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, -1, 0], # Î·\n",
    "              [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, -1, 1], # Î·'\n",
    "              [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, -1, 0],\n",
    "              [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, -1, 0],\n",
    "              [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, -1, 0],\n",
    "              [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, -1, 0],\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0],     # f2\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0],     # a2(1320)\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, -1, 0],    # Ï€2\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, -1, 0],    # Î·2(1645)\n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1],     # a2(1700) \n",
    "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, -1, 1],    # Î·2(1870)\n",
    "              [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0.5, 0, -1, 0],\n",
    "              [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0.5, 0, -1, 0],\n",
    "              [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0.5, 0, -1, 0],\n",
    "              [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0.5, 0, -1, 0],\n",
    "              [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0.5, 0, -1, 0], # K-short\n",
    "              [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0.5, 0, -1, 0], # K-long\n",
    "              [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0.5, 1, -1, 0],\n",
    "              [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0.5, 1, -1, 0],\n",
    "              [0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0.5, 1, -1, 0],\n",
    "              [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0.5, 1, -1, 0]])\n",
    "\n",
    "Y = np.array([139.57039, 139.57039, 134.9768, 547.862, 957.78, 775.4, 775.4, 775.49, 782.65, 1019.461,\n",
    "              1275.5, 1316.9, 1670.6, 1617.0, 1705.0, 1842, # unknown quark contents\n",
    "              493.677, 493.677, 497.611, 497.611, 497.614, 497.614, 891.66, 891.66, 895.55, 895.55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize log masses to have 0 mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "Y_log = np.log(Y)\n",
    "\n",
    "# Not needed if passing `normalize_y=True` when constructing GP object\n",
    "Y_normalized = scaler.fit_transform(Y_log.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the covariance function\n",
    "\n",
    "$$\\mathrm{cov}(\\mathbf{x}_i,\\mathbf{x}_j) = \\kappa(\\mathbf{x}_i,\\mathbf{x}_j) + N_{i,j} \\;, \\text{where} \\; N_{i,j} = \\sigma_y^2 \\delta_{i,j}$$\n",
    "\n",
    "where the squared exponential can be written as\n",
    "\n",
    "$$\n",
    "K_{\\textrm{SE}}(\\mathbf{x}_i,\\mathbf{x}_j) =\n",
    "\\sigma_f^2 \\exp\\left(-\\frac{1}{2l^2}\n",
    "  (\\mathbf{x}_i - \\mathbf{x}_j)^T\n",
    "  (\\mathbf{x}_i - \\mathbf{x}_j)\\right)\n",
    "$$\n",
    "\n",
    "and the rational quadratic kernel is\n",
    "\n",
    "$$\n",
    "K_{\\textrm{RQ}}(\\mathbf{x}_i,\\mathbf{x}_j) =\n",
    "\\sigma_f^2 \\exp\\left(1 + \\frac{1}{2 \\alpha}\n",
    "  (\\mathbf{x}_i - \\mathbf{x}_j)^T\n",
    "  (\\mathbf{x}_i - \\mathbf{x}_j)\\right)^{-\\alpha}\n",
    "$$\n",
    "\n",
    "The prior's covariance is specified by the kernel function. The prior mean is assumed to be data's mean if `normalize_y=True` is passed, and set to constant and $0$ otherwise. \n",
    "\n",
    "Hyperparameters of the kernel are optimized during fitting by maximizing the log-marginal-likelihood, based on the passed optimizer. Optimizer can be started repeatedly by specifying the `n_restarts_optimizer` parameter, as it may have multiple local optima.\n",
    "\n",
    "Starting from the initial hyperparameter values of the kernel, subsequent runs are conducted from hyperparameter values that have been chosen randomly from the range of allowed values.\n",
    "\n",
    "The noise level in the targets can be specified by passing it via the parameter `alpha`, either globally as a scalar or per datapoint. This is added to the diagonal of the kernel matrix during fitting. It can also be interpreted as the variance of additional Gaussian measurement noise on the training observations.\n",
    "\n",
    "The `RBF`/`SE` kernel only has an `l` parameter which corresponds to the `length_scale` parameter. To have a $\\sigma_f$ parameter as well, we have to compose the `RBF` kernel with a `ConstantKernel`. `l` can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs X (anisotropic variant of the kernel).\n",
    "\n",
    "The `RationalQuadratic` kernel is parameterized by a length scale parameter $l > 0$ and a scale mixture parameter $\\alpha > 0$. Only the isotropic variant where `length_scale` is a scalar is supported by `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Y_log or Y_normalized to (-1, 1) if adding noise\n",
    "Y_log = Y_log.reshape(-1, 1)\n",
    "Y_normalized = Y_normalized.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.296347305073987, 0.6286352637696876)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Y_log), np.std(Y_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 1.4**2\n",
    "rbf = ConstantKernel(0.6) * RBF(length_scale=1.2)\n",
    "# rq = ConstantKernel(1.0) * RationalQuadratic(length_scale=1.0, alpha=1.0)\n",
    "\n",
    "# Set GP prior to training data's mean and cov with kernel\n",
    "gpr = GaussianProcessRegressor(kernel=rbf, alpha=noise, n_restarts_optimizer=10)#, normalize_y=True)\n",
    "# gpr = GaussianProcessRegressor(kernel=rq, alpha=noise**2, normalize_y=True)\n",
    "\n",
    "# Add noise if needed\n",
    "# Y_noisy = Y_log + noise * np.random.randn(*X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Meson-Baryon Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train:  (196, 14) X_Test:  (7, 14) Y_train:  (196,) Y_test:  (7,)\n",
      "Y_test:  [6.84404 6.84542 7.01722 7.08118 7.08393 7.08795 7.11639]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = data, target \n",
    "\n",
    "print('X_Train: ', X_train.shape, 'X_Test: ', X_test.shape, 'Y_train: ', Y_train.shape, 'Y_test: ', Y_test.shape)\n",
    "print('Y_test: ', Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: 80-20 Meson Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_Train:  (156, 14) X_Test:  (40, 14) Y_train:  (156,) Y_test:  (40,)\n",
      "Y_test:  [7.62315307 7.14834574 7.45007957 7.41878088 7.28961052 9.30500489\n",
      " 4.93857064 7.42093812 7.76004068 7.24636808 7.62315307 7.41577698\n",
      " 7.85131092 7.81010935 7.26283896 7.25911613 6.71417053 7.59337419\n",
      " 6.86461811 7.48211892 6.88755257 9.24524409 9.23556553 7.44132039\n",
      " 8.33009223 8.27568198 6.79743805 8.39412119 9.26141364 7.06475903\n",
      " 7.21081845 7.42093812 8.34069465 7.17011954 7.57250299 7.32974969\n",
      " 7.26710664 7.53350653 7.44132039 8.24858145]\n"
     ]
    }
   ],
   "source": [
    "# 80-20 train-test split\n",
    "# Replace the Y's with Y_log, Y_normalized, or Y_noisy as needed\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.2, shuffle=True)\n",
    "\n",
    "print('X_Train: ', X_train.shape, 'X_Test: ', X_test.shape, 'Y_train: ', Y_train.shape, 'Y_test: ', Y_test.shape)\n",
    "print('Y_test: ', Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938.2721072927486"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: Convert changing normalized log value back to MeV scale\n",
    "np.exp(Y_test[0])\n",
    "\n",
    "# np.exp((-0.13763566 * np.std(Y_log)) + np.mean(Y_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training to find posterior mean and covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(ground_truth, prediction, cov):\n",
    "    # Plot the mean and variances\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Set font size\n",
    "    FONT_MEDIUM = 20\n",
    "    plt.rc('axes', labelsize=FONT_MEDIUM)    # fontsize of the x and y labelsb\n",
    "\n",
    "    ax.scatter(ground_truth, prediction)\n",
    "    ax.errorbar(ground_truth, prediction, yerr=cov, linestyle='None')\n",
    "    ax.set_ylabel('Predicted mass (MeV, Log Scale)')\n",
    "    ax.set_xlabel('Measured mass (MeV, Log Scale)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((192, 14), (192,), (4, 14), (4,))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1035.71997017 1424.36697623 2111.28906187 2392.88370562] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271016 0.30944669 0.33651497 0.33112907] \n",
      "\n",
      "RMSE:  0.08372310499910762\n",
      "length scale, sigma_f, noise: 22.9319519257659 8.01511232608773 1.9599999999999997\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Declare cache\n",
    "# results = {'mean': np.zeros((iter, X_test.shape[0])), 'cov': np.zeros((iter, X_test.shape[0])),\n",
    "#            'length_scales': np.zeros(iter), 'sigma_f': np.zeros(iter)}\n",
    "\n",
    "# Reuse training data\n",
    "gpr.fit(X_train, Y_train)\n",
    "\n",
    "mean, cov = gpr.predict(X_test, return_std=True)\n",
    "\n",
    "# Obtain optimized kernel parameters\n",
    "l = gpr.kernel_.k2.get_params()['length_scale']\n",
    "sigma_f = np.sqrt(gpr.kernel_.k1.get_params()['constant_value'])\n",
    "\n",
    "print(np.exp(mean), '\\n', np.exp(Y_test), '\\n', cov, '\\n')\n",
    "print('RMSE: ', mean_absolute_error(Y_test, mean))\n",
    "print('length scale, sigma_f, noise:', l, sigma_f, noise)\n",
    "\n",
    "# Plot\n",
    "plotter(Y_test, mean, cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 0.6, length_scale: 0.6\n",
      "[1035.71956308 1424.36714335 2111.28913312 2392.88382389] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271023 0.30944672 0.33651496 0.33112906] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 0.7, length_scale: 0.7\n",
      "[1035.71961471 1424.36720106 2111.28915034 2392.88383005] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651494 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 0.7999999999999999, length_scale: 0.7999999999999999\n",
      "[1035.71962627 1424.36721091 2111.28915317 2392.88383061] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651493 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 0.8999999999999999, length_scale: 0.8999999999999999\n",
      "[1035.71938731 1424.36702397 2111.28910015 2392.88382358] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271026 0.30944675 0.336515   0.3311291 ] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 0.9999999999999999, length_scale: 0.9999999999999999\n",
      "[1035.71961231 1424.36719735 2111.2891492  2392.88382949] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651494 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 1.0999999999999999, length_scale: 1.0999999999999999\n",
      "[1035.71971678 1424.36738226 2111.28920672 2392.88386025] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271018 0.30944667 0.33651488 0.33112899] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 1.1999999999999997, length_scale: 1.1999999999999997\n",
      "[2093.09213055 2093.09824355 2093.09909313 2093.10001259] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.10102953 0.10102923 0.10102909 0.10102911] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 1.2999999999999998, length_scale: 1.2999999999999998\n",
      "[1035.7197139  1424.36721898 2111.28915249 2392.88381697] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271019 0.30944669 0.33651493 0.33112903] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 1.4, length_scale: 1.4\n",
      "[1035.7197465  1424.3672181  2111.28915095 2392.88381085] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271019 0.30944669 0.33651492 0.33112903] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 1.4999999999999998, length_scale: 1.4999999999999998\n",
      "[1035.7196161  1424.36719716 2111.28914899 2392.88382876] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651494 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 1.5999999999999996, length_scale: 1.5999999999999996\n",
      "[1035.71964586 1424.36717321 2111.28913988 2392.88381696] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651494 0.33112905] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 1.6999999999999997, length_scale: 1.6999999999999997\n",
      "[1035.71965983 1424.36719492 2111.28914656 2392.88382027] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651494 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 1.7999999999999998, length_scale: 1.7999999999999998\n",
      "[1035.71958812 1424.3671662  2111.28913976 2392.8838255 ] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271022 0.30944671 0.33651495 0.33112905] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 1.9, length_scale: 1.9\n",
      "[1035.72017727 1424.36865689 2111.28961317 2392.88411908] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271003 0.30944646 0.33651453 0.33112866] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 1.9999999999999996, length_scale: 1.9999999999999996\n",
      "[1035.71960794 1424.36719076 2111.28914717 2392.88382851] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271022 0.30944671 0.33651494 0.33112905] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 2.0999999999999996, length_scale: 2.0999999999999996\n",
      "[1035.71972934 1424.36761994 2111.28928532 2392.88392174] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271017 0.30944664 0.33651482 0.33112894] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 2.1999999999999997, length_scale: 2.1999999999999997\n",
      "[1035.71968959 1424.36729768 2111.28917961 2392.88384246] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271019 0.30944668 0.33651491 0.33112901] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 2.3, length_scale: 2.3\n",
      "[1035.71959708 1424.3671742  2111.28914208 2392.88382603] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271022 0.30944671 0.33651495 0.33112905] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 2.3999999999999995, length_scale: 2.3999999999999995\n",
      "[1035.7196124  1424.3671963  2111.28914885 2392.8838292 ] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651494 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 2.4999999999999996, length_scale: 2.4999999999999996\n",
      "[1035.71966051 1424.3674194  2111.28922124 2392.88388036] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271019 0.30944667 0.33651488 0.33112899] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 2.5999999999999996, length_scale: 2.5999999999999996\n",
      "[1035.71957529 1424.36714445 2111.28913301 2392.88382198] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271022 0.30944672 0.33651495 0.33112906] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 2.6999999999999997, length_scale: 2.6999999999999997\n",
      "[1035.71958306 1424.36706733 2111.28910705 2392.88379989] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271023 0.30944672 0.33651497 0.33112908] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 2.7999999999999994, length_scale: 2.7999999999999994\n",
      "[1035.71961128 1424.36714347 2111.28913131 2392.88381522] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271022 0.30944671 0.33651495 0.33112906] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 2.8999999999999995, length_scale: 2.8999999999999995\n",
      "[1035.71935752 1424.36684948 2111.28904323 2392.88378215] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271028 0.30944678 0.33651504 0.33112914] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 2.9999999999999996, length_scale: 2.9999999999999996\n",
      "[1035.71773283 1424.36457933 2111.28835021 2392.8834663 ] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.3227107  0.30944724 0.33651573 0.33112979] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 3.0999999999999996, length_scale: 3.0999999999999996\n",
      "[1035.71969041 1424.36732851 2111.28918984 2392.88385058] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271019 0.30944668 0.3365149  0.33112901] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 3.1999999999999997, length_scale: 3.1999999999999997\n",
      "[1035.71917808 1424.3666247  2111.28897532 2392.88375422] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271032 0.30944683 0.33651511 0.33112921] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 3.2999999999999994, length_scale: 3.2999999999999994\n",
      "[1035.71961647 1424.36720162 2111.28915046 2392.88382989] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651494 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 3.3999999999999995, length_scale: 3.3999999999999995\n",
      "[1035.71961217 1424.36719259 2111.28914762 2392.88382824] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.30944671 0.33651494 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 3.4999999999999996, length_scale: 3.4999999999999996\n",
      "[1035.71846624 1424.36450633 2111.28829775 2392.8833144 ] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271058 0.30944717 0.33651569 0.33112975] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 3.599999999999999, length_scale: 3.599999999999999\n",
      "[1035.71976157 1424.36742456 2111.28921907 2392.88386351] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271017 0.30944666 0.33651487 0.33112898] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 3.6999999999999993, length_scale: 3.6999999999999993\n",
      "[1035.719628   1424.3672205  2111.2891563  2392.88383287] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651493 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 3.7999999999999994, length_scale: 3.7999999999999994\n",
      "[1035.71967983 1424.36721065 2111.28915103 2392.88382088] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.3227102  0.3094467  0.33651493 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 3.8999999999999995, length_scale: 3.8999999999999995\n",
      "[1035.71956155 1424.36711682 2111.28912435 2392.88381705] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271023 0.30944672 0.33651496 0.33112907] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 3.9999999999999996, length_scale: 3.9999999999999996\n",
      "[1035.71958058 1424.36718152 2111.28914515 2392.88383097] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271022 0.30944671 0.33651494 0.33112905] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 4.099999999999999, length_scale: 4.099999999999999\n",
      "[1035.71959536 1424.36716722 2111.28913982 2392.88382447] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271022 0.30944671 0.33651495 0.33112905] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 4.199999999999999, length_scale: 4.199999999999999\n",
      "[1035.71964391 1424.36722653 2111.28915769 2392.88383162] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651493 0.33112903] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 4.299999999999999, length_scale: 4.299999999999999\n",
      "[1035.72016121 1424.36754838 2111.28924492 2392.88382463] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.3227101  0.3094466  0.33651481 0.33112892] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 4.399999999999999, length_scale: 4.399999999999999\n",
      "[1035.71963636 1424.36720268 2111.28915005 2392.88382658] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651494 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 4.499999999999999, length_scale: 4.499999999999999\n",
      "[1035.71963281 1424.36722551 2111.28915778 2392.88383335] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651493 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 4.599999999999999, length_scale: 4.599999999999999\n",
      "[1035.71968316 1424.36721416 2111.28915207 2392.88382122] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.3227102  0.30944669 0.33651493 0.33112903] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 4.699999999999998, length_scale: 4.699999999999998\n",
      "[1035.71970869 1424.36721973 2111.28915294 2392.88381811] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.3227102  0.30944669 0.33651493 0.33112903] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 4.799999999999999, length_scale: 4.799999999999999\n",
      "[1035.71953185 1424.36710563 2111.28912177 2392.88381941] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271023 0.30944673 0.33651497 0.33112907] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 4.899999999999999, length_scale: 4.899999999999999\n",
      "[1035.71961648 1424.36720528 2111.28915167 2392.88383087] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651494 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 4.999999999999998, length_scale: 4.999999999999998\n",
      "[1035.71961074 1424.36709841 2111.28911633 2392.88380323] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271022 0.30944672 0.33651496 0.33112907] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 5.099999999999999, length_scale: 5.099999999999999\n",
      "[1035.71979316 1424.36745282 2111.28922726 2392.88386539] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271017 0.30944665 0.33651486 0.33112897] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 5.199999999999998, length_scale: 5.199999999999998\n",
      "[1035.7196187  1424.36722113 2111.28915686 2392.88383472] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271021 0.3094467  0.33651493 0.33112904] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 5.299999999999999, length_scale: 5.299999999999999\n",
      "[1035.72181654 1424.37062949 2111.29020662 2392.88435247] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32270962 0.30944603 0.33651392 0.33112809] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 5.399999999999999, length_scale: 5.399999999999999\n",
      "[1035.71953948 1424.36701587 2111.2890916  2392.88379395] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271024 0.30944674 0.33651499 0.33112909] \n",
      "\n",
      "Current hyperparams: \n",
      " noise: 1.9599999999999997, constant_value: 5.499999999999998, length_scale: 5.499999999999998\n",
      "[1035.71944995 1424.36697477 2111.28908137 2392.88379908] \n",
      " [ 980.   1370.   2535.11 2535.11] \n",
      " [0.32271026 0.30944675 0.33651501 0.33112911] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# noise = np.arange(0.05, 4.05, 0.05)\n",
    "noise = 1.4**2\n",
    "constant_value = np.arange(0.6, 5.6, 0.1)\n",
    "length_scale = np.arange(0.6, 5.6, 0.1)\n",
    "# for rq kernel\n",
    "alpha = np.arange(0.6, 5.6, 0.1)\n",
    "\n",
    "hyperparams = list(zip(constant_value, length_scale))\n",
    "\n",
    "# For writing results to file\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for counter, params in enumerate(hyperparams):\n",
    "    # Change params indexing as tuple elements are added/removed from hyperparams\n",
    "    sigma_f = params[0]\n",
    "    l = params[1]\n",
    "    print(f'Current hyperparams: \\n noise: {noise}, constant_value: {sigma_f}, length_scale: {l}')\n",
    "\n",
    "    rbf = ConstantKernel(sigma_f) * RBF(length_scale=l)\n",
    "    # rq = ConstantKernel(1.0) * RationalQuadratic(length_scale=1.0, alpha=1.0)\n",
    "\n",
    "    # Set GP prior to training data's mean and cov with kernel\n",
    "    gpr = GaussianProcessRegressor(kernel=rbf, alpha=noise, n_restarts_optimizer=10)\n",
    "\n",
    "    gpr.fit(X_train, Y_train)\n",
    "    mean, cov = gpr.predict(X_test, return_std=True)\n",
    "    \n",
    "    # Store current iteration data\n",
    "    print(np.exp(mean), '\\n', np.exp(Y_test), '\\n', cov, '\\n')\n",
    "    current_results_df = pd.DataFrame({'run': counter, 'measured': np.exp(Y_test), 'predicted': np.exp(mean), 'variance': np.exp(cov),\n",
    "                            'rmse': mean_absolute_error(Y_test, mean), 'alpha/noise': noise,\n",
    "                            'initial_length scale': l, 'initial_sigma_f': sigma_f,\n",
    "                            'trained_length_scale': gpr.kernel_.k2.get_params()['length_scale'],\n",
    "                            'trained_sigma_f': np.sqrt(gpr.kernel_.k1.get_params()['constant_value'])})\n",
    "    \n",
    "    # Draw plots\n",
    "    # plotter(Y_test, mean, cov)\n",
    "    \n",
    "    # Join dataframes to save \n",
    "    results_df = pd.concat([results_df, current_results_df])\n",
    "    \n",
    "# write to file\n",
    "results_df.round(4).to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 8)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log y_star:  [[4.93856906]]\n",
      "Predicted y_star:  [[5.76014688]]\n",
      "Predicted std:  [0.32051062]\n",
      "Test index:  [0]\n"
     ]
    }
   ],
   "source": [
    "# Leave-one-out\n",
    "loo = LeaveOneOut()\n",
    "n_splits = loo.get_n_splits(X)\n",
    "\n",
    "l = []\n",
    "mu = []\n",
    "cov = []\n",
    "sigma_f = []\n",
    "for train_index, test_index in loo.split(X):\n",
    "#     print('Train index: ', train_index, 'Test index: ', test_index)\n",
    "    X_star, X_train = X[test_index], X[train_index]\n",
    "    \n",
    "    # Replace the Y's with Y_log, Y_normalized, or Y_noisy as needed\n",
    "    Y_star, Y_train = Y_log[test_index], Y_log[train_index]\n",
    "    \n",
    "    # Reuse training data\n",
    "    gpr.fit(X_train, Y_train)\n",
    "\n",
    "    # Compute posterior mean and covariance\n",
    "    # Y_star\n",
    "    mu_s, cov_s = gpr.predict(X_star, return_std=True)\n",
    "    mu.append(mu_s)\n",
    "    cov.append(cov_s)\n",
    "    \n",
    "    print('log y_star: ', Y_star)\n",
    "    print('Predicted y_star: ', mu_s)\n",
    "    print('Predicted std: ', cov_s)\n",
    "    print('Test index: ', test_index)\n",
    "    \n",
    "    # Obtain optimized kernel parameters\n",
    "    l.append(gpr.kernel_.k2.get_params()['length_scale'])\n",
    "    sigma_f.append(np.sqrt(gpr.kernel_.k1.get_params()['constant_value']))\n",
    "    break\n",
    "\n",
    "# Plot the results\n",
    "# plot_gp(mu_s, cov_s, X, X_train=X_train, Y_train=Y_train)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
